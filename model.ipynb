{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral cloning Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def  extractFileName ( ssd_folder, abs_path):\n",
    "\n",
    "    if os.name == \"nt\":\n",
    "        split_char = '\\\\' \n",
    "    else:\n",
    "        split_char = '/' \n",
    "        \n",
    "    if '\\\\' in abs_path:\n",
    "        # \"  Windows Path \" \n",
    "#         print (\"windows path \")\n",
    "        image_name = ssd_folder\\\n",
    "                    +split_char + abs_path.split ('\\\\')[-2] \\\n",
    "                    + split_char +abs_path.split ('\\\\')[-1]\n",
    "#         print (image_name)\n",
    "\n",
    "    else:\n",
    "        # \"  Unix Path \" \n",
    "        image_name = ssd_folder \\\n",
    "                     + split_char + abs_path.split ('/')[-2] \\\n",
    "                     + split_char + abs_path.split ('/')[-1]\n",
    "#         print ( \"image_name = \" + image_name)\n",
    "    \n",
    "    return image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data folder to ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_folder = \"/ssd_data/project3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil \n",
    "\n",
    "# shutil.rmtree(ssd_folder)\n",
    "# print ( \"Copying files to ssd ....\")\n",
    "# shutil.copytree (\"data\",ssd_folder)\n",
    "# print ( \"... completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Sample Pytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_training.close()\n",
    "hdf5_validation.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "\n",
    "hdf5_training = open_file(ssd_folder + \"/training_samples.hdf5\", mode = \"w\", title = \"Training Samples\")\n",
    "hdf5_validation = open_file(ssd_folder + \"/validation_samples.hdf5\", mode = \"w\", title = \"Validation Samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the resize shape of the images ( this parameter will be used also in the Generator and in the Model definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_shape = 128\n",
    "\n",
    "## Defining the batch size:\n",
    "batch_size = 128\n",
    "\n",
    "### Defining the Queue loader chunk size  \n",
    "queue_loader_chunk = 400 # batch_size(128) * 400 , = 51200 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the two objects as images container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_samples   = hdf5_training.create_earray(hdf5_training.root, \\\n",
    "                    'training_images', \\\n",
    "                    tables.UInt8Atom(), \\\n",
    "                    shape=( 0,resized_shape, resized_shape, 3),chunkshape=(batch_size*queue_loader_chunk ,32,32,3))\n",
    "\n",
    "py_validation_samples = hdf5_validation.create_earray(hdf5_validation.root, \\\n",
    "                     'validation_images', tables.UInt8Atom(), \\\n",
    "                     shape=( 0,resized_shape, resized_shape, 3),chunkshape=(batch_size*queue_loader_chunk,32,32,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting .... \n",
      "Reading from logfile = /ssd_data/project3/run5.csv\n",
      "Reading from logfile = /ssd_data/project3/run3.csv\n",
      "Reading from logfile = /ssd_data/project3/run4.csv\n",
      "Reading from logfile = /ssd_data/project3/track1_run1.csv\n",
      "Reading from logfile = /ssd_data/project3/run2.csv\n",
      "Reading from logfile = /ssd_data/project3/run1.csv\n",
      "\n",
      "\n",
      "There are 15909 samples in total \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting .... \")\n",
    "samples_list = []\n",
    "center_image_before = None\n",
    "for name in glob.glob(ssd_folder + \"/*.csv\"):\n",
    "    print ( \"Reading from logfile = \" + name)\n",
    "    with open(name)  as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for line in reader:\n",
    "                samples_list.append([extractFileName(ssd_folder, line[0]),\\\n",
    "                                     extractFileName(ssd_folder, line[1]),\\\n",
    "                                     extractFileName(ssd_folder, line[2]),\\\n",
    "                                     float(line[3])])\n",
    "                \n",
    "print (\"\\n\\nThere are {} samples in total \".format(len(samples_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15909, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(samples_list).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding recurrent data\n",
    "\n",
    "#### Adding previous images with the CURRENT steering angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating recurrent data\n",
      ".. recurrent data processed 1000\n",
      ".. recurrent data processed 2000\n",
      ".. recurrent data processed 3000\n",
      ".. recurrent data processed 4000\n",
      ".. recurrent data processed 5000\n",
      ".. recurrent data processed 6000\n",
      ".. recurrent data processed 7000\n",
      ".. recurrent data processed 8000\n",
      ".. recurrent data processed 9000\n",
      ".. recurrent data processed 10000\n",
      ".. recurrent data processed 11000\n",
      ".. recurrent data processed 12000\n",
      ".. recurrent data processed 13000\n",
      ".. recurrent data processed 14000\n",
      ".. recurrent data processed 15000\n",
      "\n",
      "New recurrent samples created 63622\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating recurrent data\")\n",
    "samples_list_recurrent = []\n",
    "for i,line in enumerate(samples_list):\n",
    "  if i% 1000 == 0 and i> 0 : print(\".. recurrent data processed {}\".format(i))     \n",
    "  for ix in range( max(i-1,0), max(i-5,0), -1):  \n",
    "      current_steering_angle = line[3]\n",
    "        \n",
    "      samples_list_recurrent.append([samples_list[ix][0] ,samples_list[ix][1] ,samples_list[ix][2] ,line[3]]) \n",
    "#       samples_list_recurrent.append([1,1,1,.1])\n",
    "\n",
    "print (\"\\nNew recurrent samples created {}\".format(len(samples_list_recurrent)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending recurrent data to sample list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples including recurrent 79531\n"
     ]
    }
   ],
   "source": [
    "samples_list = samples_list + samples_list_recurrent\n",
    "print (\"\\nTotal samples including recurrent {}\".format(len(samples_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are 15909 images in total \n",
      "....splitted into training images = 10604  \n",
      "                  val images      = 5305  \n",
      "                  total           = 15909  \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffle(samples_list)\n",
    "\n",
    "train_list = samples_list[0:int(0.6666*len(samples_list))]\n",
    "\n",
    "val_list = samples_list[int(0.6666*len(samples_list)):int(1.0*len(samples_list))]\n",
    "\n",
    "\n",
    "print (\"\\n\\nThere are {} images in total \".format(len(samples_list)))\n",
    "print (\"....splitted into training images = {}  \".format(len(train_list)))\n",
    "print (\"                  val images      = {}  \".format(len(val_list)))\n",
    "print (\"                  total           = {}  \".format(len(train_list)+len(val_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = train_list[3400:3700 ]\n",
    "# train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_list = val_list[0:10]\n",
    "# val_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(line):\n",
    "        preprocessed_samples=[]\n",
    "        # STEERING ANGLE CALCULATION\n",
    "        correction = 0.03 # this is a parameter to tune\n",
    "        center_steering = float(line[3])\n",
    "        left_steering   = center_steering + correction\n",
    "        right_steering  = center_steering - correction\n",
    "\n",
    "        # CENTER IMAGE\n",
    "        center_image = cv2.imread(extractFileName( ssd_folder, line[0]))\n",
    "#         print (extractFileName(ssd_folder,  line[0]))\n",
    "        center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "        center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([center_image, center_steering ])\n",
    "\n",
    "        #   LEFT IMAGE\n",
    "        left_image = cv2.imread(extractFileName(ssd_folder,  line[1]))\n",
    "        left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "        left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([left_image, left_steering ])\n",
    "\n",
    "        #   RIGHT IMAGE\n",
    "        right_image = cv2.imread(extractFileName(ssd_folder,  line[2]))\n",
    "        right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "        right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([right_image, right_steering ])\n",
    "\n",
    "\n",
    "#         ###\n",
    "#         ### IMAGE AUGMENTATION\n",
    "#         ###\n",
    "#         # augmented center image\n",
    "#         preprocessed_samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "#         # augmented left image\n",
    "#         preprocessed_samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "#         # augmented right image\n",
    "#         preprocessed_samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "        \n",
    "#         print ( \"here 1 {}\".format( np.array(preprocessed_samples).shape))\n",
    "        return np.array(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing using the function defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Preprocessing the images  .... \n",
      ".. training samples processed 5000\n",
      ".. training samples processed 10000\n",
      ".. validation samples processed 1000\n",
      ".. validation samples processed 2000\n",
      ".. validation samples processed 3000\n",
      ".. validation samples processed 4000\n",
      ".. validation samples processed 5000\n",
      "\n",
      "Total training samples 128x128 after augmentation and preprocessing : 31812 \n",
      "\n",
      "Total validation samples 128x128 after augmentation and preprocessing : 15915 \n",
      "... completed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting Preprocessing the images  .... \")\n",
    "train_samples      =  np.array([]).reshape(0,2)\n",
    "validation_samples =  np.array([]).reshape(0,2)\n",
    "training_steering = []\n",
    "val_steering = []\n",
    "\n",
    "### Training\n",
    "for i,sample_line in enumerate(train_list):\n",
    "    \n",
    "#    print (sample_line)\n",
    "   for output in data_preprocess(sample_line):\n",
    "        py_training_samples.append(output[0][None])\n",
    "        training_steering.append(output[1])\n",
    "            \n",
    "   if i% 5000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "\n",
    "### Validation    \n",
    "for i,sample_line in enumerate(val_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "        py_validation_samples.append(output[0][None])\n",
    "        val_steering.append(output[1])\n",
    "\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. validation samples processed {}\".format(i))     \n",
    "\n",
    "\n",
    "print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_training_samples)) ))\n",
    "print (\"\\nTotal validation samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_validation_samples)) ))\n",
    "print ( \"... completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the table arrays and copying the labels data inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NodeError",
     "evalue": "group ``/`` already has a child node named ``training_steerings``",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNodeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-9c1ef378ea6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpy_training_steerings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf5_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training_steerings'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_steering\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpy_validation_steerings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf5_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation_steerings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_steering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tables/file.py\u001b[0m in \u001b[0;36mcreate_array\u001b[0;34m(self, where, name, obj, title, byteorder, createparents, atom, shape)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mparentnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_create_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreateparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         return Array(parentnode, name,\n\u001b[0;32m-> 1146\u001b[0;31m                      obj=obj, title=title, byteorder=byteorder)\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tables/array.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parentnode, name, obj, title, byteorder, _log, _atom)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Ordinary arrays have no filters: leaf is created with default ones.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         super(Array, self).__init__(parentnode, name, new, Filters(),\n\u001b[0;32m--> 187\u001b[0;31m                                     byteorder, _log)\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_g_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tables/leaf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parentnode, name, new, filters, byteorder, _log)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# is a lazy property that automatically handles their loading.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tables/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parentnode, name, _log)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# Only new nodes need to be referenced.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;31m# Opened nodes are already known by their parent group.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mparentnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_refnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_set_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tables/group.py\u001b[0m in \u001b[0;36m_g_refnode\u001b[0;34m(self, childnode, childname, validate)\u001b[0m\n\u001b[1;32m    514\u001b[0m             raise NodeError(\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34m\"group ``%s`` already has a child node named ``%s``\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 % (self._v_pathname, childname))\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Show a warning if there is an object attribute with that name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNodeError\u001b[0m: group ``/`` already has a child node named ``training_steerings``"
     ]
    }
   ],
   "source": [
    "py_training_steerings = hdf5_training.create_array(hdf5_training.root, 'training_steerings',training_steering )\n",
    "py_validation_steerings = hdf5_validation.create_array(hdf5_validation.root, 'validation_steerings', val_steering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_images (EArray(15915, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (51200, 32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_steerings (Array(15915,)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'python'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_steerings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring the dataset ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4025233b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOMzMrBQnDjMzK8WJw8zMSvk/YAEQRp0oUnUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40252d2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the dataset complete.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "print(\"\\nExploring the dataset ...\")\n",
    " \n",
    "# It plots the histogram of an arrray of angles: [0.0,0.1, ..., -0.1]\n",
    "def plot_steering_histogram(steerings, title, num_bins=100):\n",
    "    plt.hist(steerings, num_bins)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Steering Angles')\n",
    "    plt.ylabel('# Images')\n",
    "    plt.show()\n",
    " \n",
    "# # It plots the histogram of an arrray of associative arrays of angles: [{'steering':0.1}, {'steering':0.2}, ..., {'steering':-0.1}]\n",
    "def plot_dataset_histogram(samples, title, num_bins=100):\n",
    "    steerings = []\n",
    "    for item in samples:\n",
    "#         print (item)\n",
    "        steerings.append( float(item) )\n",
    "    plot_steering_histogram(steerings, title, num_bins)\n",
    "\n",
    "samples_before = np.array(samples_list)[:,3]\n",
    "# Plot the histogram of steering angles before the image augmentation\n",
    "plot_dataset_histogram(samples_before, 'Images per steering angle BEFORE AUGMENTATION', num_bins=100)\n",
    "samples_before = []\n",
    "\n",
    "# Plot the histogram of steering angles after the image augmentation\n",
    "plot_dataset_histogram(training_steering, 'Images per steering angle AFTER AUGMENTATION', num_bins=100)\n",
    "print(\"Exploring the dataset complete.\")\n",
    "samples=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition using Keras\n",
    "\n",
    "#### NVIDIA model used\n",
    "#### Image normalization to avoid saturation and make gradients work better.\n",
    "####     Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Drop out (0.5)\n",
    "####     Fully connected: neurons: 100, activation: ELU\n",
    "####     Fully connected: neurons: 50, activation: ELU\n",
    "####     Fully connected: neurons: 10, activation: ELU\n",
    "####     Fully connected: neurons: 1 (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_crop =12\n",
      "bottom_crop =43\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping (Cropping2D)        (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 35, 62, 24)        1824      \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 16, 29, 36)        21636     \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 6, 13, 48)         43248     \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 4, 11, 64)         27712     \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 2, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout, Reshape, LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "top_crop = int(resized_shape*10/100)\n",
    "bottom_crop = int(resized_shape*34/100)\n",
    "print ( \"top_crop =\" + str(top_crop))\n",
    "print ( \"bottom_crop =\" + str(bottom_crop))\n",
    "\n",
    "# Data Preprocessing ( Normalization and mean centering)\n",
    "model.add(Cropping2D(cropping =((bottom_crop,top_crop),(0,0)), input_shape = (resized_shape,resized_shape,3), name =\"cropping\") )\n",
    "model.add(Lambda(lambda x: x/127.5 - 1. , input_shape = (resized_shape,resized_shape,3)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv1\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv2\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv3\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv4\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv5\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu'))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50, activation='elu'))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dense(10, activation='elu'))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dense(1,kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the generators .\n",
    "### This flushes the files content from disk and return it to Tensorflow for the training fit\n",
    "### The generator is repeated many times ( as many Epochs of training )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Queue Thread process\n",
    "#### Here I am creating a function that will be called in a separate thread . This simply read big Chunks from Disk ( also the Pytable ) , shuffle them, and make them at disposition of a further processer in a Python Queue.\n",
    "#### The size of this two Queue , samples_q and labels_q is defined as batch_size * 100, so for example 3200 samples\n",
    "#### The great thing about Python Queue is that , if we define the maxsize, the put instruction in case the Queue is full, will wait until will be some space free. \n",
    "#### **** This is useful to AVOID TO LOAD THE ENTIRE PYTABLE IN MEMORY ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the  Pytable into two different table with 50/50% number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_training_samples_part1.close()\n",
    "hdf5_training_samples_part2.close()\n",
    "\n",
    "hdf5_validation_samples_part1.close()\n",
    "hdf5_validation_samples_part2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "\n",
    "# Training samples part 1\n",
    "\n",
    "hdf5_training_samples_part1 = open_file(ssd_folder + \"/training_samples_part1.hdf5\", mode = \"w\", title = \"Training Samples 1\")\n",
    "py_training_samples_part1       = hdf5_training_samples_part1.create_earray(hdf5_training_samples_part1.root, \\\n",
    "                                'training_images', \\\n",
    "                                tables.UInt8Atom(), \\\n",
    "                                shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation samples part 1\n",
    "\n",
    "hdf5_validation_samples_part1 = open_file(ssd_folder + \"/validation_samples_part1.hdf5\", mode = \"w\", title = \"Val Samples 1\")\n",
    "py_validation_samples_part1      = hdf5_validation_samples_part1.create_earray(hdf5_validation_samples_part1.root, \\\n",
    "                                 'validation_images', tables.UInt8Atom(), \\\n",
    "                                 shape=( 0,resized_shape, resized_shape, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second file ( if you have a second SSD this can be put on a different Disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training samples part 2\n",
    "\n",
    "hdf5_training_samples_part2 = open_file(ssd_folder + \"/training_samples_part2.hdf5\", mode = \"w\", title = \"Training Samples 2\")\n",
    "py_training_samples_part2       = hdf5_training_samples_part2.create_earray(hdf5_training_samples_part2.root, \\\n",
    "                                'training_images', \\\n",
    "                                tables.UInt8Atom(), \\\n",
    "                                shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "# Validation samples part 2\n",
    "\n",
    "hdf5_validation_samples_part2 = open_file(ssd_folder + \"/validation_samples_part2.hdf5\", mode = \"w\", title = \"Val Samples 2\")\n",
    "py_validation_samples_part2      = hdf5_validation_samples_part2.create_earray(hdf5_validation_samples_part2.root, \\\n",
    "                                 'validation_images', tables.UInt8Atom(), \\\n",
    "                                 shape=( 0,resized_shape, resized_shape, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the py_training_samples into Part1 and Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start splitting Training Samples......\n",
      "\n",
      "Training Sample table before splitting . Nrecords = 31812\n",
      "               py_training_samples_part1 Nrecords = 15906\n",
      "               py_training_samples_part1 Nrecords = 15906\n",
      "\n",
      "... completed\n"
     ]
    }
   ],
   "source": [
    "print ( \" Start splitting Training Samples......\")\n",
    "n_rec = len(py_training_samples)\n",
    "n_rec_tr_1 =  int(n_rec * 0.5)\n",
    "n_rec_tr_2 = n_rec - n_rec_tr_1\n",
    "\n",
    "for i, training_sample in enumerate(py_training_samples):\n",
    "    if i < n_rec_tr_1:\n",
    "        py_training_samples_part1.append(training_sample[None])\n",
    "    else:\n",
    "        py_training_samples_part2.append(training_sample[None])\n",
    "\n",
    "print ( \"\\nTraining Sample table before splitting . Nrecords = {}\".format(n_rec))\n",
    "print ( \"               py_training_samples_part1 Nrecords = {}\".format(len(py_training_samples_part1)))\n",
    "print ( \"               py_training_samples_part1 Nrecords = {}\".format(len(py_training_samples_part2)))\n",
    "\n",
    "print ( \"\\n... completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20, 200))\n",
    "# plt.subplot(50, 4, 1 )\n",
    "# plt.axis('off')\n",
    "# for i, image in enumerate(py_training_samples_part1):\n",
    "#        plt.subplot(50, 4, i+2 )\n",
    "#        plt.axis('off')\n",
    "#        plt.imshow(image, cmap='gray')\n",
    "# plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting the py_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start splitting Validation Samples......\n",
      "\n",
      "Validation Sample table before splitting . Nrecords = 15915\n",
      "               py_validation_samples_part1   Nrecords = 7957\n",
      "               py_validation_samples_part2   Nrecords = 7958\n",
      "\n",
      "... completed\n"
     ]
    }
   ],
   "source": [
    "print ( \" Start splitting Validation Samples......\")\n",
    "n_rec = len(py_validation_samples)\n",
    "\n",
    "n_rec_val_1 =  int(n_rec * 0.5)\n",
    "n_rec_val_2 = n_rec - n_rec_val_1\n",
    "\n",
    "for i, validation_sample in enumerate(py_validation_samples):\n",
    "    if i < n_rec_val_1:\n",
    "        py_validation_samples_part1.append(validation_sample[None])\n",
    "    else:\n",
    "        py_validation_samples_part2.append(validation_sample[None])\n",
    "\n",
    "print ( \"\\nValidation Sample table before splitting . Nrecords = {}\".format(n_rec))\n",
    "print ( \"               py_validation_samples_part1   Nrecords = {}\".format(len(py_validation_samples_part1)))\n",
    "print ( \"               py_validation_samples_part2   Nrecords = {}\".format(len(py_validation_samples_part2)))\n",
    "\n",
    "print ( \"\\n... completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7957"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rec_val_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the steerings angle... the training labels and validation labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training steerings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15906"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rec = len(py_training_samples)\n",
    "n_rec_tr_1 =  int(n_rec * 0.5)\n",
    "n_rec_tr_2 = n_rec - n_rec_tr_1\n",
    "n_rec_tr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part1 = hdf5_training_samples_part1.create_array(\n",
    "                               hdf5_training_samples_part1.root, \n",
    "                              'training_steerings',\n",
    "                               training_steering[0:n_rec_tr_1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part2 = hdf5_training_samples_part2.create_array(\n",
    "                               hdf5_training_samples_part2.root, \n",
    "                              'training_steerings',\n",
    "                               training_steering[n_rec_tr_1:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels table before splitting . Nrecords = 31812\n",
      "               py_training_steerings_part1   Nrecords = 15906\n",
      "               py_training_steerings_part2   Nrecords = 15906\n"
     ]
    }
   ],
   "source": [
    "print ( \"Training Labels table before splitting . Nrecords = {}\".format(len(training_steering)))\n",
    "print ( \"               py_training_steerings_part1   Nrecords = {}\".format(len(py_training_steerings_part1)))\n",
    "print ( \"               py_training_steerings_part2   Nrecords = {}\".format(len(py_training_steerings_part2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation steerings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7957"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rec_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part1 = hdf5_validation_samples_part1.create_array(\n",
    "                               hdf5_validation_samples_part1.root, \n",
    "                              'validation_steerings',\n",
    "                               val_steering[0:n_rec_val_1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part2 = hdf5_validation_samples_part2.create_array(\n",
    "                               hdf5_validation_samples_part2.root, \n",
    "                              'validation_steerings',\n",
    "                               val_steering[n_rec_val_1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Labels table before splitting . Nrecords = 15915\n",
      "               py_validation_steerings_part1   Nrecords = 7957\n",
      "               py_validation_steerings_part2   Nrecords = 7958\n"
     ]
    }
   ],
   "source": [
    "print ( \"Validation Labels table before splitting . Nrecords = {}\".format(len(val_steering)))\n",
    "print ( \"               py_validation_steerings_part1   Nrecords = {}\".format(len(py_validation_steerings_part1)))\n",
    "print ( \"               py_validation_steerings_part2   Nrecords = {}\".format(len(py_validation_steerings_part2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reopening Pytables in read-only modes ( I hope it make the reading faster ! )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_training.close()\n",
    "# hdf5_validation.close()\n",
    "\n",
    "hdf5_training_samples_part1.close()\n",
    "hdf5_training_samples_part2.close()\n",
    "\n",
    "hdf5_validation_samples_part1.close()\n",
    "hdf5_validation_samples_part2.close()\n",
    "\n",
    "\n",
    "\n",
    "ssd_folder = \"/ssd_data/project3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_folder = \"/ssd_data/project3\"\n",
    "\n",
    "hdf5_training_samples_part1 = open_file(ssd_folder + \"/training_samples_part1.hdf5\", mode = \"r\", title = \"Training Samples 1\")\n",
    "py_training_samples_part1       = hdf5_training_samples_part1.get_node(hdf5_training_samples_part1.root, \\\n",
    "                                 'training_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/training_images (EArray(15906, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_training_samples_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_training_samples_part2 = open_file(ssd_folder + \"/training_samples_part2.hdf5\", mode = \"r\", title = \"Training Samples 2\")\n",
    "py_training_samples_part2       = hdf5_training_samples_part2.get_node(hdf5_training_samples_part2.root, \\\n",
    "                                 'training_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/training_images (EArray(15906, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_training_samples_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_validation_samples_part1 = open_file(ssd_folder + \"/validation_samples_part1.hdf5\", mode = \"r\", title = \"Validation Samples 1\")\n",
    "py_validation_samples_part1       = hdf5_validation_samples_part1.get_node(hdf5_validation_samples_part1.root, \\\n",
    "                                 'validation_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_images (EArray(7957, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_samples_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_validation_samples_part2 = open_file(ssd_folder + \"/validation_samples_part2.hdf5\", mode = \"r\", title = \"Validation Samples 1\")\n",
    "py_validation_samples_part2       = hdf5_validation_samples_part2.get_node(hdf5_validation_samples_part2.root, \\\n",
    "                                 'validation_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_images (EArray(7958, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_samples_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_images (EArray(7958, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_samples_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part1 =  hdf5_training_samples_part1.get_node(hdf5_training_samples_part1.root, \\\n",
    "                                 'training_steerings')\n",
    "py_training_steerings_part2 =  hdf5_training_samples_part2.get_node(hdf5_training_samples_part2.root, \\\n",
    "                                 'training_steerings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part1 =  hdf5_validation_samples_part1.get_node(hdf5_validation_samples_part1.root, \\\n",
    "                                 'validation_steerings')\n",
    "py_validation_steerings_part2 =  hdf5_validation_samples_part2.get_node(hdf5_validation_samples_part2.root, \\\n",
    "                                 'validation_steerings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_steerings (Array(7957,)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'python'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_steerings_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from time import sleep \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def read_images_into_queue(samples_q, labels_q , samples, labels):\n",
    "#     print ( \" reading images into Queue\")\n",
    "    # Define the Queue max size , the Queue.put() automatically do wait until records will be get from \n",
    "    # an other process and will free some space in the queue.\n",
    "#     From docs.python.org:\n",
    "#     The Queue module implements multi-producer, multi-consumer queues. \n",
    "#     It is especially useful in threaded programming when information must be exchanged safely between multiple threads. \n",
    "#     The Queue class in this module implements all the required locking semantics. \n",
    "#     It depends on the availability of thread support in Python; see the threading module.\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 200))\n",
    "    plt.subplot(100, 4, 1 )\n",
    "    plt.axis('off')\n",
    "\n",
    "    numsamples = len(samples)\n",
    "#     print (\" Samples shape \" + str(samples.shape))\n",
    "#     print (\" Numsamples = \" + str(numsamples))\n",
    "    step = batch_size*queue_loader_chunk\n",
    "\n",
    "    i = 0\n",
    "    while 1:  ### remember you need to stop the process !!\n",
    "#         print (\"numsamples = \" + str(numsamples))\n",
    "        for offset in range(0, numsamples, step):\n",
    "            # loading into memory a BIG chunk of data ( 32* queue_loader_chunk  )\n",
    "            chunk_batch_samples = samples[offset:offset+step]\n",
    "            chunk_batch_labels  = labels[offset:offset+step]\n",
    "            \n",
    "            # SHUFFLE !! REALLY IMPORTANT !!\n",
    "            chunk_batch_samples, chunk_batch_labels = shuffle(chunk_batch_samples, chunk_batch_labels )\n",
    "            for sample, steering in zip ( chunk_batch_samples,chunk_batch_labels):\n",
    "                samples_q.put(sample)\n",
    "                labels_q.put(steering)\n",
    "#                 sleep (0.1)\n",
    "            plt.show()  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the reading processes -- from Disk to Memory Queue\n",
    "#### Remember to TERMINATE them !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_producer1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-d5fffc314fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_producer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_producer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_producer1' is not defined"
     ]
    }
   ],
   "source": [
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_images (EArray(7957, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_samples_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_steerings (Array(7957,)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'python'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_steerings_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for steering in py_training_steerings_part1:\n",
    "#     print ( \"steering = \" + str(steering ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "training_samples_q = Queue(maxsize = 70)\n",
    "# training_samples_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "\n",
    "# training_labels_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "training_labels_q = Queue(maxsize = 70)\n",
    "\n",
    "validation_samples_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "validation_labels_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "\n",
    "###############################################################\n",
    "# Training Producers . They load training data into Queues\n",
    "# ###############################################################\n",
    "training_producer1 = Process(target=read_images_into_queue, \n",
    "                            args=(training_samples_q,            # <-- Training images queue\n",
    "                                  training_labels_q,             # <-- Training labels queue\n",
    "                                  py_training_samples_part1,           # <-- Training samples Pytable\n",
    "                                  py_training_steerings_part1))        # <-- Training labels  Pytable\n",
    "training_producer1.start()\n",
    "\n",
    "training_producer2 = Process(target=read_images_into_queue, \n",
    "                            args=(training_samples_q,            # <-- Training images queue\n",
    "                                  training_labels_q,             # <-- Training labels queue\n",
    "                                  py_training_samples_part2,           # <-- Training samples Pytable\n",
    "                                  py_training_steerings_part2))        # <-- Training labels  Pytable\n",
    "training_producer2.start()\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# Validation Producers. They load validation data into Queues\n",
    "###############################################################\n",
    "validation_producer1 = Process(target=read_images_into_queue, \n",
    "                            args=(validation_samples_q,              # <-- Training images queue\n",
    "                                  validation_labels_q,               # <-- Training labels queue\n",
    "                                  py_validation_samples_part1,           # <-- Training samples Pytable\n",
    "                                  py_validation_steerings_part1))        # <-- Training labels  Pytable\n",
    "validation_producer1.start()\n",
    "\n",
    "validation_producer2 = Process(target=read_images_into_queue, \n",
    "                            args=(validation_samples_q,              # <-- Training images queue\n",
    "                                  validation_labels_q,               # <-- Training labels queue\n",
    "                                  py_validation_samples_part2,           # <-- Training samples Pytable\n",
    "                                  py_validation_steerings_part2))        # <-- Training labels  Pytable\n",
    "validation_producer2.start()\n",
    "\n",
    "\n",
    "## training_producer1.terminate()\n",
    "## training_producer2.terminate()\n",
    "\n",
    "## validation_producer1.terminate()\n",
    "## validation_producer2.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_samples_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(py_training_samples_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples_q.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_loader_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining thread safe generator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import threading\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def generator(samples_q, labels_q, batch_size ):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(20, 200))\n",
    "# #     plt.subplot(50, 4, 1 )\n",
    "#     plt.axis('off')\n",
    "#     for i, image in enumerate(py_training_samples_part1):\n",
    "#            plt.subplot(50, 4, i+2 )\n",
    "#            plt.axis('off')\n",
    "#            plt.imshow(image, cmap='gray')\n",
    "#     plt.show()  \n",
    "    read_nb = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        \n",
    "        images = []\n",
    "        angles=[]\n",
    "        for i in range(0, batch_size):\n",
    "            image = samples_q.get()\n",
    "            steering = labels_q.get()\n",
    "#             plt.imshow(image)\n",
    "#             plt.title(steering)\n",
    "#             plt.show()\n",
    "            images.append(image)\n",
    "            angles.append(steering)\n",
    "\n",
    "        yield np.array(images) , np.array(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Train and Validation generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the traing_generator uses Queue and async thread !\n",
    "train_generator      = generator(training_samples_q, \n",
    "                                 training_labels_q, \n",
    "                                 batch_size)\n",
    "\n",
    "validation_generator = generator(validation_samples_q, \n",
    "                                 validation_labels_q, \n",
    "                                 batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model using traing_generator and validating with validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "numper_of_train_samples      = len(py_training_samples)\n",
    "number_of_validation_samples = len(py_validation_samples) \n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= \\\n",
    "                                     numper_of_train_samples/batch_size, \n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     validation_steps=number_of_validation_samples/batch_size, \n",
    "                                     epochs=epochs, verbose = 1,\\\n",
    "                                     workers=2)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nTotal number of train samples: {} ( shape {}x{})'.format(numper_of_train_samples,resized_shape,resized_shape))\n",
    "print('\\nBatch Size                   : {}'.format(batch_size))\n",
    "print('\\nDuration                     : {}'.format(end_time - start_time))\n",
    "\n",
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"model.h5\")\n",
    "print ( \"  \")\n",
    "print ( \" .. model saved to model.h5 \")\n",
    "print ( \"  \")\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "# print(history_object.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# # # Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Convolution broken down in small pieces \n",
    "\n",
    "### Here I am trying to visualize the Convolution Layers to understand visually how many filters I should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print (\" Loading drive.h5 .......\")\n",
    "\n",
    "# from keras.models import load_model\n",
    "# from keras.models import Model\n",
    "\n",
    "# modelobj = load_model('drive.h5')\n",
    "# print (\" ..... model drive.h5 successfully loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this purpose I am loading a Test image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(py_training_samples_part1[3000], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load test images\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# test_images = []\n",
    "\n",
    "# image = cv2.imread('./test_images/center1.jpg')\n",
    "# image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "# test_images.append(image)\n",
    "\n",
    "\n",
    "# test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I am looking at the Image Crop if is well done in the right position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'cropping'\n",
    "# intermediate_layer_model = Model(inputs=modelobj.input,\n",
    "#                                  outputs=modelobj.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# intermediate_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Show the cropped images\n",
    "# def show_intermediate_output(image_ori, intermediate_output):\n",
    "#     print (intermediate_output.shape)\n",
    "#     depth = 0 \n",
    "#     %matplotlib inline\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(20, 100))\n",
    "#     new_image = []\n",
    "#     plt.subplot(40, 5, 1 )\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image_ori)\n",
    "#     for i in range(0,intermediate_output[0,0].shape[0]):\n",
    "#            single_output = intermediate_output[:,:,i]\n",
    "# #            print ( \"single_output.shape {}\".format(single_output.shape ))\n",
    "# #            print ( single_output)\n",
    "#            plt.subplot(40, 5, i+2 )\n",
    "#            plt.axis('off')\n",
    "#            single_output = single_output.astype(np.uint8)\n",
    "#            plt.imshow(single_output, cmap='gray')\n",
    "#     plt.show()    \n",
    "\n",
    "    \n",
    "# show_intermediate_output(test_images[0], intermediate_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the FIRST convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv1'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the SECOND convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv2'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv3'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv4'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from keras.utils.visualize_util import plot\n",
    "# from keras.models import load_model\n",
    "# %matplotlib inline\n",
    "\n",
    "# #visualize the model\n",
    "# modelobj = load_model('model.h5')\n",
    "# plot (modelobj, to_file='model.png')\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(100, 100))\n",
    "# image = cv2.imread('model.png')\n",
    "# image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "# plt.subplot(5, 5, 1)\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
