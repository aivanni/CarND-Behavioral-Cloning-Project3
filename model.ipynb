{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the .csv containing the file names and the steering angles\n",
    "\n",
    "### Loading the file names  and steering angles into samples\n",
    "### Splitting samples into train and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  extractFileName ( abs_path):\n",
    "\n",
    "    import os\n",
    "    if os.name == \"nt\":\n",
    "        split_char = '\\\\' \n",
    "    else:\n",
    "        split_char = '/' \n",
    "    if '\\\\' in abs_path:\n",
    "        # \"  Windows Path \" \n",
    "        image_name = abs_path.split ('\\\\')[-3] \\\n",
    "                            + split_char + abs_path.split ('\\\\')[-2] \\\n",
    "                            + split_char + abs_path.split ('\\\\')[-1]\n",
    "\n",
    "    else:\n",
    "        # \"  Unix Path \" \n",
    "        image_name = abs_path.split ('/')[-3] \\\n",
    "                            + split_char + abs_path.split ('/')[-2] \\\n",
    "                            + split_char + abs_path.split ('/')[-1]\n",
    "    \n",
    "    return image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the resize shape of the images ( this parameter will be used also in the Generator and in the Model definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_shape = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the PyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = open_file(\"./data/samples.hdf5\", mode = \"w\", title = \"Samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the two objects as images container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_samples = hdf5_file.create_earray(hdf5_file.root, \\\n",
    "                    'train_img', \\\n",
    "                    tables.UInt8Atom(), \\\n",
    "                    shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "py_validation_samples      = hdf5_file.create_earray(hdf5_file.root, \\\n",
    "                     'val_img', tables.UInt8Atom(), \\\n",
    "                     shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting .... \")\n",
    "samples_list = []\n",
    "center_image_before = None\n",
    "for name in glob.glob(\"./data/*.csv\"):\n",
    "    print ( \"Reading from logfile = \" + name)\n",
    "    with open(name)  as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for line in reader:\n",
    "                # STEERING ANGLE CALCULATION\n",
    "                samples_list.append([extractFileName( line[0]),\\\n",
    "                                     extractFileName( line[1]),\\\n",
    "                                     extractFileName( line[2]),\\\n",
    "                                     float(line[3])])\n",
    "                \n",
    "samples_list = np.array(samples_list)\n",
    "\n",
    "from random import shuffle\n",
    "shuffle(samples_list)\n",
    "\n",
    "train_list = samples_list[0:int(0.8*len(samples_list))]\n",
    "\n",
    "val_list = samples_list[int(0.8*len(samples_list)):int(1.0*len(samples_list))]\n",
    "\n",
    "\n",
    "print (\"\\n\\nThere are {} images in total \".format(len(samples_list)))\n",
    "print (\"....splitted into training images = {}  \".format(len(train_list)))\n",
    "print (\"                  val images      = {}  \".format(len(val_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = train_list[0:100 ]\n",
    "# train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(line):\n",
    "        preprocessed_samples=[]\n",
    "        # STEERING ANGLE CALCULATION\n",
    "        correction = 0.03 # this is a parameter to tune\n",
    "        center_steering = float(line[3])\n",
    "        left_steering   = center_steering + correction\n",
    "        right_steering  = center_steering - correction\n",
    "\n",
    "        # CENTER IMAGE\n",
    "        center_image = cv2.imread(extractFileName( line[0]))\n",
    "        center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "        center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([center_image, center_steering ])\n",
    "\n",
    "        #   LEFT IMAGE\n",
    "        left_image = cv2.imread(extractFileName( line[1]))\n",
    "        left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "        left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([left_image, left_steering ])\n",
    "\n",
    "        #   RIGHT IMAGE\n",
    "        right_image = cv2.imread(extractFileName( line[2]))\n",
    "        right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "        right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([right_image, right_steering ])\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### IMAGE AUGMENTATION\n",
    "        ###\n",
    "        # augmented center image\n",
    "        preprocessed_samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "        # augmented left image\n",
    "        preprocessed_samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "        # augmented right image\n",
    "        preprocessed_samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "        \n",
    "#         print ( \"here 1 {}\".format( np.array(preprocessed_samples).shape))\n",
    "        return np.array(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing using the function defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting Preprocessing the images  .... \")\n",
    "train_samples      =  np.array([]).reshape(0,2)\n",
    "validation_samples =  np.array([]).reshape(0,2)\n",
    "training_steering = []\n",
    "val_steering = []\n",
    "\n",
    "for i,sample_line in enumerate(train_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "#         print (output[0].shape)\n",
    "        py_training_samples.append(output[0][None])\n",
    "        training_steering.append(output[1])\n",
    "          \n",
    "   if i% 1000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "   \n",
    "for i,sample_line in enumerate(val_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "#         print ( \"output[0].shape\" + str(output[0].shape))\n",
    "        py_validation_samples.append(output[0][None])\n",
    "        val_steering.append(output[1])\n",
    "#         print (output[0][None].shape)\n",
    "\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. validation samples processed {}\".format(i))     \n",
    "\n",
    "\n",
    "print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_training_samples)) ))\n",
    "print (\"\\nTotal validation samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_validation_samples)) ))\n",
    "print ( \"... completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the table arrays and copying the labels data inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings = hdf5_file.create_array(hdf5_file.root, 'py_training_steering',training_steering )\n",
    "py_validation_steerings = hdf5_file.create_array(hdf5_file.root, 'py_val_steering', val_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "print(\"\\nExploring the dataset ...\")\n",
    " \n",
    "# It plots the histogram of an arrray of angles: [0.0,0.1, ..., -0.1]\n",
    "def plot_steering_histogram(steerings, title, num_bins=100):\n",
    "    plt.hist(steerings, num_bins)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Steering Angles')\n",
    "    plt.ylabel('# Images')\n",
    "    plt.show()\n",
    " \n",
    "# # It plots the histogram of an arrray of associative arrays of angles: [{'steering':0.1}, {'steering':0.2}, ..., {'steering':-0.1}]\n",
    "def plot_dataset_histogram(samples, title, num_bins=100):\n",
    "    steerings = []\n",
    "    for item in samples:\n",
    "#         print (item)\n",
    "        steerings.append( float(item) )\n",
    "    plot_steering_histogram(steerings, title, num_bins)\n",
    "\n",
    "samples_before = samples_list[:,3]\n",
    "# Plot the histogram of steering angles before the image augmentation\n",
    "plot_dataset_histogram(samples_before, 'Images per steering angle BEFORE AUGMENTATION', num_bins=100)\n",
    "samples_before = []\n",
    "\n",
    "# Plot the histogram of steering angles after the image augmentation\n",
    "plot_dataset_histogram(training_steering, 'Images per steering angle AFTER AUGMENTATION', num_bins=100)\n",
    "print(\"Exploring the dataset complete.\")\n",
    "samples=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition using Keras\n",
    "\n",
    "#### NVIDIA model used\n",
    "#### Image normalization to avoid saturation and make gradients work better.\n",
    "####     Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Drop out (0.5)\n",
    "####     Fully connected: neurons: 100, activation: ELU\n",
    "####     Fully connected: neurons: 50, activation: ELU\n",
    "####     Fully connected: neurons: 10, activation: ELU\n",
    "####     Fully connected: neurons: 1 (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout, Reshape\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "top_crop = int(resized_shape*10/100)\n",
    "bottom_crop = int(resized_shape*34/100)\n",
    "\n",
    "# Data Preprocessing ( Normalization and mean centering)\n",
    "model.add(Cropping2D(cropping =((bottom_crop,top_crop),(0,0)), input_shape = (resized_shape,resized_shape,3), name =\"cropping\") )\n",
    "model.add(Lambda(lambda x: x/127.5 - 1. , input_shape = (resized_shape,resized_shape,3)))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv1\"))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv2\"))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv3\"))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv4\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv5\"))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(50, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(10, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(1,kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the generator .\n",
    "### This flushes the files content from disk and return it to Tensorflow for the training fit\n",
    "### The generator is repeated many times ( as many Epochs of training )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Queue Thread process\n",
    "#### Here I am creating a function that will be called in a separate thread . This simply read big Chunks from Disk ( also the Pytable ) , shuffle them, and make them at disposition of a further processer in a Python Queue.\n",
    "#### The size of this two Queue , samples_q and labels_q is defined as batch_size * 100, so for example 3200 samples\n",
    "#### The great thing about Python Queue is that , if we define the maxsize, the put instruction in case the Queue is full, will wait until will be some space free. \n",
    "#### **** This is useful to AVOID TO LOAD THE ENTIRE PYTABLE IN MEMORY ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the batch size:\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def read_images_into_queue(samples_q, labels_q , samples, labels):\n",
    "    print ( \" reading images into Queue\")\n",
    "    # Define the Queue max size , the Queue.put() automatically do wait until records will be get from \n",
    "    # an other process and will free some space in the queue.\n",
    "#     From docs.python.org:\n",
    "#     The Queue module implements multi-producer, multi-consumer queues. \n",
    "#     It is especially useful in threaded programming when information must be exchanged safely between multiple threads. \n",
    "#     The Queue class in this module implements all the required locking semantics. \n",
    "#     It depends on the availability of thread support in Python; see the threading module.\n",
    "    \n",
    "    numsamples = len(samples)\n",
    "    while 1:  ### remember you need to stop the process !!\n",
    "        print (\"numsamples = \" + str(numsamples))\n",
    "        for offset in range(0, numsamples, batch_size*100):\n",
    "             print ( \"offset = \" + str(offset))\n",
    "             # loading into memory a BIG chunk of data ( 3200 samples )\n",
    "             chunk_batch_samples = samples[offset:offset+batch_size*100]\n",
    "             chunk_batch_labels  = labels[offset:offset+batch_size*100]\n",
    "             print (\"chunk_batch_samples size {}\".format(chunk_batch_samples.shape) )\n",
    "             # shuffle the chunk\n",
    "             chunk_batch_samples,chunk_batch_labels = sklearn.utils.shuffle(chunk_batch_samples,chunk_batch_labels)  \n",
    "             for sample, steering in zip ( chunk_batch_samples,chunk_batch_labels):\n",
    "                samples_q.put(sample)\n",
    "                labels_q.put(steering)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def generator(samples_q, labels_q, batch_size ):\n",
    "    read_nb = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        \n",
    "        images = []\n",
    "        angles=[]\n",
    "        for i in range(0, batch_size):\n",
    "            images.append(samples_q.get())\n",
    "            angles.append(labels_q.get())\n",
    "\n",
    "        yield np.array(images) , np.array(angles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the reading process -- from Disk to Memory Queue\n",
    "#### Remember to TERMINATE it !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "training_samples_q = Queue(maxsize = batch_size * 100)\n",
    "training_labels_q = Queue(maxsize = batch_size * 100)\n",
    "\n",
    "validation_samples_q = Queue(maxsize = batch_size * 100)\n",
    "validation_labels_q = Queue(maxsize = batch_size * 100)\n",
    "\n",
    "###############################################################\n",
    "# Training Producer. It loads training data into Queues\n",
    "###############################################################\n",
    "training_producer = Process(target=read_images_into_queue, \n",
    "                            args=(training_samples_q,            # <-- Training images queue\n",
    "                                  training_labels_q,             # <-- Training labels queue\n",
    "                                  py_training_samples,           # <-- Training samples Pytable\n",
    "                                  py_training_steerings))        # <-- Training labels  Pytable\n",
    "training_producer.start()\n",
    "\n",
    "###############################################################\n",
    "# Validation Producer. It loads validation data into Queues\n",
    "###############################################################\n",
    "validation_producer = Process(target=read_images_into_queue, \n",
    "                            args=(validation_samples_q,              # <-- Training images queue\n",
    "                                  validation_labels_q,               # <-- Training labels queue\n",
    "                                  py_validation_samples,           # <-- Training samples Pytable\n",
    "                                  py_validation_steerings))        # <-- Training labels  Pytable\n",
    "validation_producer.start()\n",
    "\n",
    "\n",
    "## training_producer.terminate()\n",
    "## validation_producer.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# producer.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Train and Validation generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the traing_generator uses Queue and async thread !\n",
    "train_generator      = generator(training_samples_q, \n",
    "                                 training_labels_q, \n",
    "                                 batch_size)\n",
    "\n",
    "validation_generator = generator(validation_samples_q, \n",
    "                                 validation_steerings_q, \n",
    "                                 batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model using traing_generator and validating with validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "numper_of_train_samples      = len(py_training_samples)\n",
    "number_of_validation_samples = len(py_val_samples) \n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= \\\n",
    "                                     numper_of_train_samples/batch_size, \n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     validation_steps=number_of_validation_samples/batch_size, \n",
    "                                     epochs=epochs, verbose = 1,\\\n",
    "                                     workers=1)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nTotal number of train samples: {} ( shape {}x{})'.format(numper_of_train_samples,resized_shape,resized_shape))\n",
    "print('\\nBatch Size                   : {}'.format(batch_size))\n",
    "print('\\nDuration                     : {}'.format(end_time - start_time))\n",
    "\n",
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"selfdrive_model.h5\")\n",
    "print ( \"  \")\n",
    "print ( \" .. model saved to selfdrive_model.h5 \")\n",
    "print ( \"  \")\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# # # Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Convolution broken down in small pieces \n",
    "\n",
    "### Here I am trying to visualize the Convolution Layers to understand visually how many filters I should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\" Loading drive.h5 .......\")\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "modelobj = load_model('drive.h5')\n",
    "print (\" ..... model drive.h5 successfully loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this purpose I am loading a Test image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load test images\n",
    "import cv2\n",
    "import numpy as np\n",
    "test_images = []\n",
    "\n",
    "image = cv2.imread('./test_images/center1.jpg')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "test_images.append(image)\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I am looking at the Image Crop if is well done in the right position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'cropping'\n",
    "intermediate_layer_model = Model(inputs=modelobj.input,\n",
    "                                 outputs=modelobj.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "intermediate_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the cropped images\n",
    "def show_intermediate_output(image_ori, intermediate_output):\n",
    "    print (intermediate_output.shape)\n",
    "    depth = 0 \n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 100))\n",
    "    new_image = []\n",
    "    plt.subplot(40, 5, 1 )\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_ori)\n",
    "    for i in range(0,intermediate_output[0,0].shape[0]):\n",
    "           single_output = intermediate_output[:,:,i]\n",
    "#            print ( \"single_output.shape {}\".format(single_output.shape ))\n",
    "#            print ( single_output)\n",
    "           plt.subplot(40, 5, i+2 )\n",
    "           plt.axis('off')\n",
    "           single_output = single_output.astype(np.uint8)\n",
    "           plt.imshow(single_output, cmap='gray')\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "show_intermediate_output(test_images[0], intermediate_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the FIRST convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv1'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the SECOND convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv2'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv3'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv4'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "\n",
    "#visualize the model\n",
    "modelobj = load_model('model.h5')\n",
    "plot (modelobj, to_file='model.png')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(100, 100))\n",
    "image = cv2.imread('model.png')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(5, 5, 1)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
