{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the .csv containing the file names and the steering angles\n",
    "\n",
    "### Loading the file names  and steering angles into samples\n",
    "### Splitting samples into train and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  extractFileName ( abs_path):\n",
    "\n",
    "    import os\n",
    "    if os.name == \"nt\":\n",
    "        split_char = '\\\\' \n",
    "    else:\n",
    "        split_char = '/' \n",
    "    if '\\\\' in abs_path:\n",
    "        # \"  Windows Path \" \n",
    "        image_name = abs_path.split ('\\\\')[-3] \\\n",
    "                            + split_char + abs_path.split ('\\\\')[-2] \\\n",
    "                            + split_char + abs_path.split ('\\\\')[-1]\n",
    "\n",
    "    else:\n",
    "        # \"  Unix Path \" \n",
    "        image_name = abs_path.split ('/')[-3] \\\n",
    "                            + split_char + abs_path.split ('/')[-2] \\\n",
    "                            + split_char + abs_path.split ('/')[-1]\n",
    "\n",
    "    return image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the resize shape of the images ( this parameter will be used also in the Generator and in the Model definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_shape = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING ALL IMAGES CENTER, LEFT, RIGHT IN A TWO DIMENSIONAL ARRAY:\n",
    "## ( IMAGE, STEERING ANGLE )\n",
    "## EVERYTHING WILL BE KEPT IN MEMORY TO SPEED DATA FLUSHING BETWEEN CPU AND GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the PyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = open_file(\"./data/samples.npy\", mode = \"w\", title = \"Samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved\n",
    "# check the order of data and chose proper data shape to save images\n",
    "if data_order == 'th':\n",
    "    data_shape = ( 0,3, resized_shape, resized_shape)\n",
    "elif data_order == 'tf':\n",
    "    data_shape = ( 0,resized_shape, resized_shape, 3)\n",
    "    \n",
    "\n",
    "####h5file.create_array(h5file.root, 'steering_angle', train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the two objects as images container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_storage = hdf5_file.create_earray(hdf5_file.root, 'train_img', img_dtype, shape=data_shape)\n",
    "val_storage = hdf5_file.create_earray(hdf5_file.root, 'val_img', img_dtype, shape=data_shape)\n",
    "traing_steering = hdf5_file.create_earray(hdf5_file.root, 'traing_steering', img_dtype, shape=(0,1))\n",
    "val_steering = hdf5_file.create_earray(hdf5_file.root, 'val_steering', img_dtype, shape=(0,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "import cv2\n",
    "import numpy as np\n",
    "test_images = []\n",
    "\n",
    "image = cv2.imread('./test_images/center1.jpg')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "train_storage.append(image[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_storage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting .... \n",
      "Reading from logfile = ./data/run1.csv\n",
      "\n",
      "\n",
      "There are 1779 images in total \n",
      "....splitted into training images = 1423  \n",
      "                  val images      = 356  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting .... \")\n",
    "samples_list = []\n",
    "center_image_before = None\n",
    "for name in glob.glob(\"./data/run1.csv\"):\n",
    "    print ( \"Reading from logfile = \" + name)\n",
    "    with open(name)  as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for line in reader:\n",
    "                # STEERING ANGLE CALCULATION\n",
    "                samples_list.append([extractFileName( line[0]),\\\n",
    "                                     extractFileName( line[1]),\\\n",
    "                                     extractFileName( line[2]),\\\n",
    "                                     float(line[3])])\n",
    "                \n",
    "samples_list = np.array(samples_list)\n",
    "\n",
    "from random import shuffle\n",
    "shuffle(samples_list)\n",
    "\n",
    "train_list = samples_list[0:int(0.8*len(samples_list))]\n",
    "\n",
    "val_list = samples_list[int(0.8*len(samples_list)):int(1.0*len(samples_list))]\n",
    "\n",
    "\n",
    "print (\"\\n\\nThere are {} images in total \".format(len(samples_list)))\n",
    "print (\"....splitted into training images = {}  \".format(len(train_list)))\n",
    "print (\"                  val images      = {}  \".format(len(val_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(line):\n",
    "        preprocessed_samples=[]\n",
    "        # STEERING ANGLE CALCULATION\n",
    "        correction = 0.03 # this is a parameter to tune\n",
    "        center_steering = float(line[3])\n",
    "        left_steering   = center_steering + correction\n",
    "        right_steering  = center_steering - correction\n",
    "\n",
    "        # CENTER IMAGE\n",
    "        center_image = cv2.imread(extractFileName( line[0]))\n",
    "        center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "        center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([center_image, center_steering ])\n",
    "\n",
    "        #   LEFT IMAGE\n",
    "        left_image = cv2.imread(extractFileName( line[1]))\n",
    "        left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "        left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([left_image, left_steering ])\n",
    "\n",
    "        #   RIGHT IMAGE\n",
    "        right_image = cv2.imread(extractFileName( line[2]))\n",
    "        right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "        right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([right_image, right_steering ])\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### IMAGE AUGMENTATION\n",
    "        ###\n",
    "        # augmented center image\n",
    "        preprocessed_samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "        # augmented left image\n",
    "        preprocessed_samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "        # augmented right image\n",
    "        preprocessed_samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "        \n",
    "#         print ( \"here 1 {}\".format( np.array(preprocessed_samples).shape))\n",
    "        return np.array(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-d825030247eb>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-d825030247eb>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    traing_steering.append(output[1][None]))\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html\n",
    "    \n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting Preprocessing the images  .... \")\n",
    "train_samples      =  np.array([]).reshape(0,2)\n",
    "validation_samples =  np.array([]).reshape(0,2)\n",
    "\n",
    "for i,sample_line in enumerate(train_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "        train_storage.append(output[0][None])\n",
    "        traing_steering.append(output[1][None]))\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "   \n",
    "for i,sample_line in enumerate(val_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "        val_storage.append(output[0][None])\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. validation samples processed {}\".format(i))     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(train_storage)) ))\n",
    "print (\"\\nTotal validation samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(val_storage)) ))\n",
    "print ( \"... completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting .... \n",
      "Reading from logfile = ./data/run1.csv\n",
      "\n",
      "Total samples 128x128 loaded in memory  : 37356 , size occupied in memory : 24 Mb\n",
      "\n",
      "Train samples = 29883\n",
      "\n",
      "Validation samples  = 7473\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import csv\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import glob\n",
    "\n",
    "# print ( \"Starting .... \")\n",
    "# samples = []\n",
    "# center_image_before = None\n",
    "# for name in glob.glob(\"./data/run1.csv\"):\n",
    "#     print ( \"Reading from logfile = \" + name)\n",
    "#     with open(name)  as csvfile:\n",
    "#             reader = csv.reader(csvfile)\n",
    "#             for line in reader:\n",
    "#                 # STEERING ANGLE CALCULATION\n",
    "#                 correction = 0.03 # this is a parameter to tune\n",
    "#                 center_steering = float(line[3])\n",
    "#                 left_steering   = center_steering + correction\n",
    "#                 right_steering  = center_steering - correction\n",
    "                \n",
    "#                 # CENTER IMAGE\n",
    "#                 center_image = cv2.imread(extractFileName( line[0]))\n",
    "#                 center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "#                 center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "#                 samples.append([center_image, center_steering ])\n",
    "                \n",
    "#                 #   LEFT IMAGE\n",
    "#                 left_image = cv2.imread(extractFileName( line[1]))\n",
    "#                 left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "#                 left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "#                 samples.append([left_image, left_steering ])\n",
    "                \n",
    "#                 #   RIGHT IMAGE\n",
    "#                 right_image = cv2.imread(extractFileName( line[2]))\n",
    "#                 right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "#                 right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "#                 samples.append([right_image, right_steering ])\n",
    "\n",
    "                \n",
    "#                 ###\n",
    "#                 ### IMAGE AUGMENTATION\n",
    "#                 ###\n",
    "#                 # augmented center image\n",
    "#                 samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "#                 # augmented left image\n",
    "#                 samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "#                 # augmented right image\n",
    "#                 samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "\n",
    "                \n",
    "#                 ###\n",
    "#                 ### IMAGE AUGMENTATION 2 - \n",
    "#                 ### Adding images of frames before... with the actual steering wheel angle\n",
    "#                 if center_image_before is not None:\n",
    "#                     samples.append([center_image_before, center_steering ])\n",
    " \n",
    "#                 center_image_before = center_image\n",
    "    \n",
    "\n",
    "# samples =np.array(samples)\n",
    "                \n",
    "# print (\"\\nTotal samples {}x{} loaded in memory  : {} , size occupied in memory : {} Mb\"\\\n",
    "#        .format(resized_shape,resized_shape,\\\n",
    "#         str(len(samples)*3), int(samples.nbytes/8/1024)) )\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "# print (\"\\nTrain samples = {}\".format(train_samples.shape[0]*3))\n",
    "# print (\"\\nValidation samples  = {}\".format(validation_samples.shape[0]*3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring the dataset ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlbKCcLMzEo5QZiZWan/A+6dIEdMtbtMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbba78dce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "print(\"\\nExploring the dataset ...\")\n",
    " \n",
    "# # It plots the histogram of an arrray of angles: [0.0,0.1, ..., -0.1]\n",
    "# def plot_steering_histogram(steerings, title, num_bins=100):\n",
    "#     plt.hist(steerings, num_bins)\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel('Steering Angles')\n",
    "#     plt.ylabel('# Images')\n",
    "#     plt.show()\n",
    " \n",
    "# # It plots the histogram of an arrray of associative arrays of angles: [{'steering':0.1}, {'steering':0.2}, ..., {'steering':-0.1}]\n",
    "def plot_dataset_histogram(samples, title, num_bins=100):\n",
    "    steerings = []\n",
    "    for item in samples:\n",
    "#         print (item)\n",
    "        steerings.append( float(item) )\n",
    "    plot_steering_histogram(steerings, title, num_bins)\n",
    "\n",
    "samples_before = samples_list[:,3]\n",
    "# Plot the histogram of steering angles before the image augmentation\n",
    "plot_dataset_histogram(samples_before, 'Images per steering angle BEFORE AUGMENTATION', num_bins=100)\n",
    "samples_before = []\n",
    "\n",
    "# Plot the histogram of steering angles after the image augmentation\n",
    "plot_dataset_histogram(samples[:,1], 'Images per steering angle AFTER AUGMENTATION', num_bins=100)\n",
    "print(\"Exploring the dataset complete.\")\n",
    "samples=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.0', '0.0', '0.0', ..., '0.04117647', '-0.02941176', '0.06470589'],\n",
       "      dtype='<U44')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_list[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the generator .\n",
    "### This flushes the files content from disk and return it to Tensorflow for the training fit\n",
    "### The generator is repeated many times ( as many Epochs of training )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "\n",
    "def generator(generator_samples, batch_size, shape ):\n",
    "    num_samples = len(generator_samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = generator_samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                images.append(batch_sample[0])\n",
    "                angles.append(batch_sample[1])\n",
    "\n",
    "            # end of the batch, yield the images gathered\n",
    "            yield sklearn.utils.shuffle(np.array(images) , np.array(angles))\n",
    "            #return sklearn.utils.shuffle(X_train ) #, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NVIDIA model used\n",
    "#### Image normalization to avoid saturation and make gradients work better.\n",
    "####     Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Drop out (0.5)\n",
    "####     Fully connected: neurons: 100, activation: ELU\n",
    "####     Fully connected: neurons: 50, activation: ELU\n",
    "####     Fully connected: neurons: 10, activation: ELU\n",
    "####     Fully connected: neurons: 1 (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout, Reshape\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "top_crop = int(resized_shape*10/100)\n",
    "bottom_crop = int(resized_shape*34/100)\n",
    "\n",
    "# Data Preprocessing ( Normalization and mean centering)\n",
    "model.add(Cropping2D(cropping =((bottom_crop,top_crop),(0,0)), input_shape = (resized_shape,resized_shape,3), name =\"cropping\") )\n",
    "model.add(Lambda(lambda x: x/127.5 - 1. , input_shape = (resized_shape,resized_shape,3)))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv1\"))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv2\"))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv3\"))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv4\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv5\"))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(50, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(10, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(1,kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training and printing a statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Train and Validation generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator      = generator(train_samples, batch_size, shape=resized_shape)\n",
    "validation_generator = generator(validation_samples, batch_size, shape=resized_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model using traing_generator and validating with validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "numper_of_train_samples      = len(train_samples)\n",
    "number_of_validation_samples = len(validation_samples) \n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= \\\n",
    "            numper_of_train_samples/batch_size, validation_data=validation_generator, \\\n",
    "            validation_steps=number_of_validation_samples/batch_size, epochs=epochs, verbose = 1)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nTotal number of train samples: {} ( shape {}x{})'.format(numper_of_train_samples,resized_shape,resized_shape))\n",
    "print('\\nBatch Size                   : {}'.format(batch_size))\n",
    "print('\\nDuration                     : {}'.format(end_time - start_time))\n",
    "\n",
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"drive.h5\")\n",
    "print ( \"  \")\n",
    "print ( \" .. model saved to drive.h5 \")\n",
    "print ( \"  \")\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# # # Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Convolution broken down in small pieces \n",
    "\n",
    "### Here I am trying to visualize the Convolution Layers to understand visually how many filters I should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\" Loading drive.h5 .......\")\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "modelobj = load_model('drive.h5')\n",
    "print (\" ..... model drive.h5 successfully loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this purpose I am loading a Test image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load test images\n",
    "import cv2\n",
    "import numpy as np\n",
    "test_images = []\n",
    "\n",
    "image = cv2.imread('./test_images/center1.jpg')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "test_images.append(image)\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I am looking at the Image Crop if is well done in the right position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'cropping'\n",
    "intermediate_layer_model = Model(inputs=modelobj.input,\n",
    "                                 outputs=modelobj.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "intermediate_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the cropped images\n",
    "def show_intermediate_output(image_ori, intermediate_output):\n",
    "    print (intermediate_output.shape)\n",
    "    depth = 0 \n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 100))\n",
    "    new_image = []\n",
    "    plt.subplot(40, 5, 1 )\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_ori)\n",
    "    for i in range(0,intermediate_output[0,0].shape[0]):\n",
    "           single_output = intermediate_output[:,:,i]\n",
    "#            print ( \"single_output.shape {}\".format(single_output.shape ))\n",
    "#            print ( single_output)\n",
    "           plt.subplot(40, 5, i+2 )\n",
    "           plt.axis('off')\n",
    "           single_output = single_output.astype(np.uint8)\n",
    "           plt.imshow(single_output, cmap='gray')\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "show_intermediate_output(test_images[0], intermediate_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the FIRST convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv1'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the SECOND convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv2'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv3'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv4'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "\n",
    "#visualize the model\n",
    "modelobj = load_model('model.h5')\n",
    "plot (modelobj, to_file='model.png')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(100, 100))\n",
    "image = cv2.imread('model.png')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(5, 5, 1)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
