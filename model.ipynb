{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral cloning Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def  extractFileName ( ssd_folder, abs_path):\n",
    "\n",
    "    if os.name == \"nt\":\n",
    "        split_char = '\\\\' \n",
    "    else:\n",
    "        split_char = '/' \n",
    "        \n",
    "    if '\\\\' in abs_path:\n",
    "        # \"  Windows Path \" \n",
    "#         print (\"windows path \")\n",
    "        image_name = ssd_folder\\\n",
    "                    +split_char + abs_path.split ('\\\\')[-2] \\\n",
    "                    + split_char +abs_path.split ('\\\\')[-1]\n",
    "#         print (image_name)\n",
    "\n",
    "    else:\n",
    "        # \"  Unix Path \" \n",
    "        image_name = ssd_folder \\\n",
    "                     + split_char + abs_path.split ('/')[-2] \\\n",
    "                     + split_char + abs_path.split ('/')[-1]\n",
    "#         print ( \"image_name = \" + image_name)\n",
    "    \n",
    "    return image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data folder to ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_folder = \"/ssd_data/project3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil \n",
    "\n",
    "# shutil.rmtree(ssd_folder)\n",
    "# print ( \"Copying files to ssd ....\")\n",
    "# shutil.copytree (\"data\",ssd_folder)\n",
    "# print ( \"... completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Sample Pytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "\n",
    "hdf5_file = open_file(ssd_folder + \"/samples.hdf5\", mode = \"w\", title = \"Samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the resize shape of the images ( this parameter will be used also in the Generator and in the Model definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_shape = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the batch size:\n",
    "batch_size = 128\n",
    "\n",
    "### Defining the Queue loader chunk size  \n",
    "queue_loader_chunk = 100 # batch_size(32) * 1000 samples, = 32000 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the two objects as images container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_samples = hdf5_file.create_earray(hdf5_file.root, \\\n",
    "                    'train_img', \\\n",
    "                    tables.UInt8Atom(), \\\n",
    "                    shape=( 0,resized_shape, resized_shape, 3),chunkshape=(batch_size*queue_loader_chunk ,32,32,3))\n",
    "\n",
    "py_validation_samples      = hdf5_file.create_earray(hdf5_file.root, \\\n",
    "                     'val_img', tables.UInt8Atom(), \\\n",
    "                     shape=( 0,resized_shape, resized_shape, 3),chunkshape=(batch_size*queue_loader_chunk,32,32,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting .... \n",
      "Reading from logfile = /ssd_data/project3/run5.csv\n",
      "Reading from logfile = /ssd_data/project3/run3.csv\n",
      "Reading from logfile = /ssd_data/project3/run4.csv\n",
      "Reading from logfile = /ssd_data/project3/track1_run1.csv\n",
      "Reading from logfile = /ssd_data/project3/run2.csv\n",
      "Reading from logfile = /ssd_data/project3/run1.csv\n",
      "\n",
      "\n",
      "There are 15909 samples in total \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting .... \")\n",
    "samples_list = []\n",
    "center_image_before = None\n",
    "for name in glob.glob(ssd_folder + \"/*.csv\"):\n",
    "    print ( \"Reading from logfile = \" + name)\n",
    "    with open(name)  as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for line in reader:\n",
    "                samples_list.append([extractFileName(ssd_folder, line[0]),\\\n",
    "                                     extractFileName(ssd_folder, line[1]),\\\n",
    "                                     extractFileName(ssd_folder, line[2]),\\\n",
    "                                     float(line[3])])\n",
    "                \n",
    "print (\"\\n\\nThere are {} samples in total \".format(len(samples_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15909, 4)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(samples_list).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding recurrent data\n",
    "\n",
    "#### Adding previous images with the CURRENT steering angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating recurrent data\n",
      ".. recurrent data processed 1000\n",
      ".. recurrent data processed 2000\n",
      ".. recurrent data processed 3000\n",
      ".. recurrent data processed 4000\n",
      ".. recurrent data processed 5000\n",
      ".. recurrent data processed 6000\n",
      ".. recurrent data processed 7000\n",
      ".. recurrent data processed 8000\n",
      ".. recurrent data processed 9000\n",
      ".. recurrent data processed 10000\n",
      ".. recurrent data processed 11000\n",
      ".. recurrent data processed 12000\n",
      ".. recurrent data processed 13000\n",
      ".. recurrent data processed 14000\n",
      ".. recurrent data processed 15000\n",
      "\n",
      "New recurrent samples created 63622\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating recurrent data\")\n",
    "samples_list_recurrent = []\n",
    "for i,line in enumerate(samples_list):\n",
    "  if i% 1000 == 0 and i> 0 : print(\".. recurrent data processed {}\".format(i))     \n",
    "  for ix in range( max(i-1,0), max(i-5,0), -1):  \n",
    "      current_steering_angle = line[3]\n",
    "        \n",
    "      samples_list_recurrent.append([samples_list[ix][0] ,samples_list[ix][1] ,samples_list[ix][2] ,line[3]]) \n",
    "#       samples_list_recurrent.append([1,1,1,.1])\n",
    "\n",
    "print (\"\\nNew recurrent samples created {}\".format(len(samples_list_recurrent)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending recurrent data to sample list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples including recurrent 79531\n"
     ]
    }
   ],
   "source": [
    "samples_list = samples_list + samples_list_recurrent\n",
    "print (\"\\nTotal samples including recurrent {}\".format(len(samples_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are 79531 images in total \n",
      "....splitted into training images = 63624  \n",
      "                  val images      = 15907  \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffle(samples_list)\n",
    "\n",
    "train_list = samples_list[0:int(0.8*len(samples_list))]\n",
    "\n",
    "val_list = samples_list[int(0.8*len(samples_list)):int(1.0*len(samples_list))]\n",
    "\n",
    "\n",
    "print (\"\\n\\nThere are {} images in total \".format(len(samples_list)))\n",
    "print (\"....splitted into training images = {}  \".format(len(train_list)))\n",
    "print (\"                  val images      = {}  \".format(len(val_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = train_list[3400:3700 ]\n",
    "# train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_list = val_list[0:10]\n",
    "# val_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(line):\n",
    "        preprocessed_samples=[]\n",
    "        # STEERING ANGLE CALCULATION\n",
    "        correction = 0.03 # this is a parameter to tune\n",
    "        center_steering = float(line[3])\n",
    "        left_steering   = center_steering + correction\n",
    "        right_steering  = center_steering - correction\n",
    "\n",
    "        # CENTER IMAGE\n",
    "        center_image = cv2.imread(extractFileName( ssd_folder, line[0]))\n",
    "#         print (extractFileName(ssd_folder,  line[0]))\n",
    "        center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "        center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([center_image, center_steering ])\n",
    "\n",
    "        #   LEFT IMAGE\n",
    "        left_image = cv2.imread(extractFileName(ssd_folder,  line[1]))\n",
    "        left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "        left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([left_image, left_steering ])\n",
    "\n",
    "        #   RIGHT IMAGE\n",
    "        right_image = cv2.imread(extractFileName(ssd_folder,  line[2]))\n",
    "        right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "        right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([right_image, right_steering ])\n",
    "\n",
    "\n",
    "#         ###\n",
    "#         ### IMAGE AUGMENTATION\n",
    "#         ###\n",
    "#         # augmented center image\n",
    "#         preprocessed_samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "#         # augmented left image\n",
    "#         preprocessed_samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "#         # augmented right image\n",
    "#         preprocessed_samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "        \n",
    "#         print ( \"here 1 {}\".format( np.array(preprocessed_samples).shape))\n",
    "        return np.array(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing using the function defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Preprocessing the images  .... \n",
      ".. training samples processed 1000\n",
      ".. training samples processed 2000\n",
      ".. training samples processed 3000\n",
      ".. training samples processed 4000\n",
      ".. training samples processed 5000\n",
      ".. training samples processed 6000\n",
      ".. training samples processed 7000\n",
      ".. training samples processed 8000\n",
      ".. training samples processed 9000\n",
      ".. training samples processed 10000\n",
      ".. training samples processed 11000\n",
      ".. training samples processed 12000\n",
      ".. training samples processed 13000\n",
      ".. training samples processed 14000\n",
      ".. training samples processed 15000\n",
      ".. training samples processed 16000\n",
      ".. training samples processed 17000\n",
      ".. training samples processed 18000\n",
      ".. training samples processed 19000\n",
      ".. training samples processed 20000\n",
      ".. training samples processed 21000\n",
      ".. training samples processed 22000\n",
      ".. training samples processed 23000\n",
      ".. training samples processed 24000\n",
      ".. training samples processed 25000\n",
      ".. training samples processed 26000\n",
      ".. training samples processed 27000\n",
      ".. training samples processed 28000\n",
      ".. training samples processed 29000\n",
      ".. training samples processed 30000\n",
      ".. training samples processed 31000\n",
      ".. training samples processed 32000\n",
      ".. training samples processed 33000\n",
      ".. training samples processed 34000\n",
      ".. training samples processed 35000\n",
      ".. training samples processed 36000\n",
      ".. training samples processed 37000\n",
      ".. training samples processed 38000\n",
      ".. training samples processed 39000\n",
      ".. training samples processed 40000\n",
      ".. training samples processed 41000\n",
      ".. training samples processed 42000\n",
      ".. training samples processed 43000\n",
      ".. training samples processed 44000\n",
      ".. training samples processed 45000\n",
      ".. training samples processed 46000\n",
      ".. training samples processed 47000\n",
      ".. training samples processed 48000\n",
      ".. training samples processed 49000\n",
      ".. training samples processed 50000\n",
      ".. training samples processed 51000\n",
      ".. training samples processed 52000\n",
      ".. training samples processed 53000\n",
      ".. training samples processed 54000\n",
      ".. training samples processed 55000\n",
      ".. training samples processed 56000\n",
      ".. training samples processed 57000\n",
      ".. training samples processed 58000\n",
      ".. training samples processed 59000\n",
      ".. training samples processed 60000\n",
      ".. training samples processed 61000\n",
      ".. training samples processed 62000\n",
      ".. training samples processed 63000\n",
      ".. validation samples processed 1000\n",
      ".. validation samples processed 2000\n",
      ".. validation samples processed 3000\n",
      ".. validation samples processed 4000\n",
      ".. validation samples processed 5000\n",
      ".. validation samples processed 6000\n",
      ".. validation samples processed 7000\n",
      ".. validation samples processed 8000\n",
      ".. validation samples processed 9000\n",
      ".. validation samples processed 10000\n",
      ".. validation samples processed 11000\n",
      ".. validation samples processed 12000\n",
      ".. validation samples processed 13000\n",
      ".. validation samples processed 14000\n",
      ".. validation samples processed 15000\n",
      "\n",
      "Total training samples 128x128 after augmentation and preprocessing : 193432 \n",
      "\n",
      "Total validation samples 128x128 after augmentation and preprocessing : 47721 \n",
      "... completed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting Preprocessing the images  .... \")\n",
    "train_samples      =  np.array([]).reshape(0,2)\n",
    "validation_samples =  np.array([]).reshape(0,2)\n",
    "training_steering = []\n",
    "val_steering = []\n",
    "\n",
    "### Training\n",
    "for i,sample_line in enumerate(train_list):\n",
    "    \n",
    "#    print (sample_line)\n",
    "   for output in data_preprocess(sample_line):\n",
    "        py_training_samples.append(output[0][None])\n",
    "        training_steering.append(output[1])\n",
    "            \n",
    "   if i% 1000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "\n",
    "### Validation    \n",
    "for i,sample_line in enumerate(val_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "        py_validation_samples.append(output[0][None])\n",
    "        val_steering.append(output[1])\n",
    "\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. validation samples processed {}\".format(i))     \n",
    "\n",
    "\n",
    "print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_training_samples)) ))\n",
    "print (\"\\nTotal validation samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_validation_samples)) ))\n",
    "print ( \"... completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the table arrays and copying the labels data inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings = hdf5_file.create_array(hdf5_file.root, 'py_training_steering',training_steering )\n",
    "py_validation_steerings = hdf5_file.create_array(hdf5_file.root, 'py_val_steering', val_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring the dataset ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncVIxM7PKOKmYmVll/j+A83NfDZqswAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4671d695c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4678066cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the dataset complete.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "print(\"\\nExploring the dataset ...\")\n",
    " \n",
    "# It plots the histogram of an arrray of angles: [0.0,0.1, ..., -0.1]\n",
    "def plot_steering_histogram(steerings, title, num_bins=100):\n",
    "    plt.hist(steerings, num_bins)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Steering Angles')\n",
    "    plt.ylabel('# Images')\n",
    "    plt.show()\n",
    " \n",
    "# # It plots the histogram of an arrray of associative arrays of angles: [{'steering':0.1}, {'steering':0.2}, ..., {'steering':-0.1}]\n",
    "def plot_dataset_histogram(samples, title, num_bins=100):\n",
    "    steerings = []\n",
    "    for item in samples:\n",
    "#         print (item)\n",
    "        steerings.append( float(item) )\n",
    "    plot_steering_histogram(steerings, title, num_bins)\n",
    "\n",
    "samples_before = np.array(samples_list)[:,3]\n",
    "# Plot the histogram of steering angles before the image augmentation\n",
    "plot_dataset_histogram(samples_before, 'Images per steering angle BEFORE AUGMENTATION', num_bins=100)\n",
    "samples_before = []\n",
    "\n",
    "# Plot the histogram of steering angles after the image augmentation\n",
    "plot_dataset_histogram(training_steering, 'Images per steering angle AFTER AUGMENTATION', num_bins=100)\n",
    "print(\"Exploring the dataset complete.\")\n",
    "samples=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition using Keras\n",
    "\n",
    "#### NVIDIA model used\n",
    "#### Image normalization to avoid saturation and make gradients work better.\n",
    "####     Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Drop out (0.5)\n",
    "####     Fully connected: neurons: 100, activation: ELU\n",
    "####     Fully connected: neurons: 50, activation: ELU\n",
    "####     Fully connected: neurons: 10, activation: ELU\n",
    "####     Fully connected: neurons: 1 (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_crop =12\n",
      "bottom_crop =43\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping (Cropping2D)        (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 35, 62, 24)        1824      \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 16, 29, 36)        21636     \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 6, 13, 48)         43248     \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 4, 11, 64)         27712     \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 2, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout, Reshape, LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "top_crop = int(resized_shape*10/100)\n",
    "bottom_crop = int(resized_shape*34/100)\n",
    "print ( \"top_crop =\" + str(top_crop))\n",
    "print ( \"bottom_crop =\" + str(bottom_crop))\n",
    "\n",
    "# Data Preprocessing ( Normalization and mean centering)\n",
    "model.add(Cropping2D(cropping =((bottom_crop,top_crop),(0,0)), input_shape = (resized_shape,resized_shape,3), name =\"cropping\") )\n",
    "model.add(Lambda(lambda x: x/127.5 - 1. , input_shape = (resized_shape,resized_shape,3)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv1\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv2\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv3\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv4\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv5\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu'))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50, activation='elu'))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dense(10, activation='elu'))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dense(1,kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the generators .\n",
    "### This flushes the files content from disk and return it to Tensorflow for the training fit\n",
    "### The generator is repeated many times ( as many Epochs of training )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Queue Thread process\n",
    "#### Here I am creating a function that will be called in a separate thread . This simply read big Chunks from Disk ( also the Pytable ) , shuffle them, and make them at disposition of a further processer in a Python Queue.\n",
    "#### The size of this two Queue , samples_q and labels_q is defined as batch_size * 100, so for example 3200 samples\n",
    "#### The great thing about Python Queue is that , if we define the maxsize, the put instruction in case the Queue is full, will wait until will be some space free. \n",
    "#### **** This is useful to AVOID TO LOAD THE ENTIRE PYTABLE IN MEMORY ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the  Pytable into two different table with 50/50% number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdf5_file_part1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-5820a14dd4ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhdf5_file_part1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhdf5_file_part2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hdf5_file_part1' is not defined"
     ]
    }
   ],
   "source": [
    "hdf5_file_part1.close()\n",
    "hdf5_file_part2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "\n",
    "hdf5_file_part1 = open_file(ssd_folder + \"/samples_part1.hdf5\", mode = \"w\", title = \"Samples_part1\")\n",
    "py_training_samples_part1       = hdf5_file_part1.create_earray(hdf5_file_part1.root, \\\n",
    "                                'train_img', \\\n",
    "                                tables.UInt8Atom(), \\\n",
    "                                shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "py_validation_samples_part1      = hdf5_file_part1.create_earray(hdf5_file_part1.root, \\\n",
    "                                 'val_img', tables.UInt8Atom(), \\\n",
    "                                 shape=( 0,resized_shape, resized_shape, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second file ( if you have a second SSD this can be put on a different Disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_part2 = open_file(ssd_folder + \"/samples_part2.hdf5\", mode = \"w\", title = \"Samples_part1\")\n",
    "py_training_samples_part2       = hdf5_file_part1.create_earray(hdf5_file_part2.root, \\\n",
    "                                'train_img', \\\n",
    "                                tables.UInt8Atom(), \\\n",
    "                                shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "py_validation_samples_part2      = hdf5_file_part1.create_earray(hdf5_file_part2.root, \\\n",
    "                                 'val_img', tables.UInt8Atom(), \\\n",
    "                                 shape=( 0,resized_shape, resized_shape, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the py_training_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start splitting Training Samples......\n",
      "... completed\n",
      "\n",
      "Training Sample table before splitting . Nrecords = 193432\n",
      "               py_training_samples_part1 Nrecords = 96716\n",
      "               py_training_samples_part1 Nrecords = 96716\n"
     ]
    }
   ],
   "source": [
    "print ( \" Start splitting Training Samples......\")\n",
    "n_rec = len(py_training_samples)\n",
    "n_rec_tr_1 =  int(n_rec * 0.5)\n",
    "n_rec_tr_2 = n_rec - n_rec_tr_1\n",
    "\n",
    "for i, training_sample in enumerate(py_training_samples):\n",
    "    if i < n_rec_tr_1:\n",
    "        py_training_samples_part1.append(training_sample[None])\n",
    "    else:\n",
    "        py_training_samples_part2.append(training_sample[None])\n",
    "print ( \"... completed\")\n",
    "\n",
    "print ( \"\\nTraining Sample table before splitting . Nrecords = {}\".format(n_rec))\n",
    "print ( \"               py_training_samples_part1 Nrecords = {}\".format(len(py_training_samples_part1)))\n",
    "print ( \"               py_training_samples_part1 Nrecords = {}\".format(len(py_training_samples_part2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20, 200))\n",
    "# plt.subplot(50, 4, 1 )\n",
    "# plt.axis('off')\n",
    "# for i, image in enumerate(py_training_samples_part1):\n",
    "#        plt.subplot(50, 4, i+2 )\n",
    "#        plt.axis('off')\n",
    "#        plt.imshow(image, cmap='gray')\n",
    "# plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting the py_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start splitting Validation Samples......\n",
      "... completed\n",
      "\n",
      "Validation Sample table before splitting . Nrecords = 47721\n",
      "               py_validation_samples_part1   Nrecords = 23861\n",
      "               py_validation_samples_part2   Nrecords = 23860\n"
     ]
    }
   ],
   "source": [
    "print ( \" Start splitting Validation Samples......\")\n",
    "n_rec = len(py_validation_samples)\n",
    "\n",
    "n_rec_val_1 =  int(n_rec * 0.5)\n",
    "n_rec_val_2 = n_rec - n_rec_val_1\n",
    "\n",
    "for i, validation_sample in enumerate(py_validation_samples):\n",
    "    if i < n_rec * 0.5:\n",
    "        py_validation_samples_part1.append(validation_sample[None])\n",
    "    else:\n",
    "        py_validation_samples_part2.append(validation_sample[None])\n",
    "print ( \"... completed\")\n",
    "\n",
    "print ( \"\\nValidation Sample table before splitting . Nrecords = {}\".format(n_rec))\n",
    "print ( \"               py_validation_samples_part1   Nrecords = {}\".format(len(py_validation_samples_part1)))\n",
    "print ( \"               py_validation_samples_part2   Nrecords = {}\".format(len(py_validation_samples_part2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the steerings angle... the training labels and validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96716"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rec = len(py_training_samples)\n",
    "n_rec_tr_1 =  int(n_rec * 0.5)\n",
    "n_rec_tr_2 = n_rec - n_rec_tr_1\n",
    "n_rec_tr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part1 = hdf5_file_part1.create_array(\n",
    "                               hdf5_file_part1.root, \n",
    "                              'py_training_steering',\n",
    "                               training_steering[0:n_rec_tr_1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part2 = hdf5_file_part2.create_array(\n",
    "                               hdf5_file_part2.root, \n",
    "                              'py_training_steering',\n",
    "                               training_steering[n_rec_tr_1:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels table before splitting . Nrecords = 190872\n",
      "               py_training_steerings_part1   Nrecords = 96716\n",
      "               py_training_steerings_part2   Nrecords = 94156\n"
     ]
    }
   ],
   "source": [
    "print ( \"Training Labels table before splitting . Nrecords = {}\".format(len(training_steering)))\n",
    "print ( \"               py_training_steerings_part1   Nrecords = {}\".format(len(py_training_steerings_part1)))\n",
    "print ( \"               py_training_steerings_part2   Nrecords = {}\".format(len(py_training_steerings_part2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part1 = hdf5_file_part1.create_array(\n",
    "                               hdf5_file_part1.root, \n",
    "                              'py_validation_steering',\n",
    "                               val_steering[0:n_rec_val_1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part2 = hdf5_file_part2.create_array(\n",
    "                               hdf5_file_part2.root, \n",
    "                              'py_validation_steering',\n",
    "                               val_steering[n_rec_val_1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Labels table before splitting . Nrecords = 3182\n",
      "               py_validation_steerings_part1   Nrecords = 1591\n",
      "               py_validation_steerings_part2   Nrecords = 1591\n"
     ]
    }
   ],
   "source": [
    "print ( \"Validation Labels table before splitting . Nrecords = {}\".format(len(val_steering)))\n",
    "print ( \"               py_validation_steerings_part1   Nrecords = {}\".format(len(py_validation_steerings_part1)))\n",
    "print ( \"               py_validation_steerings_part2   Nrecords = {}\".format(len(py_validation_steerings_part2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from time import sleep \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def read_images_into_queue(samples_q, labels_q , samples, labels):\n",
    "#     print ( \" reading images into Queue\")\n",
    "    # Define the Queue max size , the Queue.put() automatically do wait until records will be get from \n",
    "    # an other process and will free some space in the queue.\n",
    "#     From docs.python.org:\n",
    "#     The Queue module implements multi-producer, multi-consumer queues. \n",
    "#     It is especially useful in threaded programming when information must be exchanged safely between multiple threads. \n",
    "#     The Queue class in this module implements all the required locking semantics. \n",
    "#     It depends on the availability of thread support in Python; see the threading module.\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 200))\n",
    "    plt.subplot(100, 4, 1 )\n",
    "    plt.axis('off')\n",
    "\n",
    "    numsamples = len(samples)\n",
    "#     print (\" Samples shape \" + str(samples.shape))\n",
    "#     print (\" Numsamples = \" + str(numsamples))\n",
    "    step = batch_size*queue_loader_chunk\n",
    "\n",
    "    i = 0\n",
    "    while 1:  ### remember you need to stop the process !!\n",
    "#         print (\"numsamples = \" + str(numsamples))\n",
    "        for offset in range(0, numsamples, step):\n",
    "            # loading into memory a BIG chunk of data ( 32* queue_loader_chunk  )\n",
    "            chunk_batch_samples = samples[offset:offset+step]\n",
    "            chunk_batch_labels  = labels[offset:offset+step]\n",
    "            chunk_batch_samples, chunk_batch_labels = shuffle(chunk_batch_samples, chunk_batch_labels )\n",
    "            for sample, steering in zip ( chunk_batch_samples,chunk_batch_labels):\n",
    "                samples_q.put(sample)\n",
    "                labels_q.put(steering)\n",
    "#                 sleep (0.1)\n",
    "            plt.show()  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the reading processes -- from Disk to Memory Queue\n",
    "#### Remember to TERMINATE them !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_producer1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-d5fffc314fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_producer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_producer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_producer1' is not defined"
     ]
    }
   ],
   "source": [
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for steering in py_training_steerings_part1:\n",
    "#     print ( \"steering = \" + str(steering ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'py_validation_steerings_part1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-1ef86946195b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                                   \u001b[0mvalidation_labels_q\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0;31m# <-- Training labels queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                   \u001b[0mpy_validation_samples_part1\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# <-- Training samples Pytable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                   py_validation_steerings_part1))        # <-- Training labels  Pytable\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mvalidation_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'py_validation_steerings_part1' is not defined"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "training_samples_q = Queue(maxsize = 70)\n",
    "# training_samples_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "\n",
    "# training_labels_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "training_labels_q = Queue(maxsize = 70)\n",
    "\n",
    "validation_samples_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "validation_labels_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "\n",
    "###############################################################\n",
    "# Training Producers . They load training data into Queues\n",
    "# ###############################################################\n",
    "training_producer1 = Process(target=read_images_into_queue, \n",
    "                            args=(training_samples_q,            # <-- Training images queue\n",
    "                                  training_labels_q,             # <-- Training labels queue\n",
    "                                  py_training_samples_part1,           # <-- Training samples Pytable\n",
    "                                  py_training_steerings_part1))        # <-- Training labels  Pytable\n",
    "training_producer1.start()\n",
    "\n",
    "# training_producer2 = Process(target=read_images_into_queue, \n",
    "#                             args=(training_samples_q,            # <-- Training images queue\n",
    "#                                   training_labels_q,             # <-- Training labels queue\n",
    "#                                   py_training_samples_part2,           # <-- Training samples Pytable\n",
    "#                                   py_training_steerings_part2))        # <-- Training labels  Pytable\n",
    "# training_producer2.start()\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# Validation Producers. They load validation data into Queues\n",
    "###############################################################\n",
    "validation_producer1 = Process(target=read_images_into_queue, \n",
    "                            args=(validation_samples_q,              # <-- Training images queue\n",
    "                                  validation_labels_q,               # <-- Training labels queue\n",
    "                                  py_validation_samples_part1,           # <-- Training samples Pytable\n",
    "                                  py_validation_steerings_part1))        # <-- Training labels  Pytable\n",
    "validation_producer1.start()\n",
    "\n",
    "# validation_producer2 = Process(target=read_images_into_queue, \n",
    "#                             args=(validation_samples_q,              # <-- Training images queue\n",
    "#                                   validation_labels_q,               # <-- Training labels queue\n",
    "#                                   py_validation_samples_part2,           # <-- Training samples Pytable\n",
    "#                                   py_validation_steerings_part2))        # <-- Training labels  Pytable\n",
    "# validation_producer2.start()\n",
    "\n",
    "\n",
    "## training_producer1.terminate()\n",
    "## training_producer2.terminate()\n",
    "\n",
    "## validation_producer1.terminate()\n",
    "## validation_producer2.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/val_img (EArray(23861, 128, 128, 3)) ''\n",
       "  atom := UInt8Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'irrelevant'\n",
       "  chunkshape := (2, 128, 128, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_validation_samples_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(py_training_samples_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples_q.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_loader_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining thread safe generator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import threading\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def generator(samples_q, labels_q, batch_size ):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(20, 200))\n",
    "# #     plt.subplot(50, 4, 1 )\n",
    "#     plt.axis('off')\n",
    "#     for i, image in enumerate(py_training_samples_part1):\n",
    "#            plt.subplot(50, 4, i+2 )\n",
    "#            plt.axis('off')\n",
    "#            plt.imshow(image, cmap='gray')\n",
    "#     plt.show()  \n",
    "    read_nb = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        \n",
    "        images = []\n",
    "        angles=[]\n",
    "        for i in range(0, batch_size):\n",
    "            image = samples_q.get()\n",
    "            steering = labels_q.get()\n",
    "#             plt.imshow(image)\n",
    "#             plt.title(steering)\n",
    "#             plt.show()\n",
    "            images.append(image)\n",
    "            angles.append(steering)\n",
    "\n",
    "        yield np.array(images) , np.array(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Train and Validation generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the traing_generator uses Queue and async thread !\n",
    "train_generator      = generator(training_samples_q, \n",
    "                                 training_labels_q, \n",
    "                                 batch_size)\n",
    "\n",
    "validation_generator = generator(validation_samples_q, \n",
    "                                 validation_labels_q, \n",
    "                                 batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model using traing_generator and validating with validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "numper_of_train_samples      = len(py_training_samples)\n",
    "number_of_validation_samples = len(py_validation_samples) \n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= \\\n",
    "                                     numper_of_train_samples/batch_size, \n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     validation_steps=number_of_validation_samples/batch_size, \n",
    "                                     epochs=epochs, verbose = 1,\\\n",
    "                                     workers=2)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nTotal number of train samples: {} ( shape {}x{})'.format(numper_of_train_samples,resized_shape,resized_shape))\n",
    "print('\\nBatch Size                   : {}'.format(batch_size))\n",
    "print('\\nDuration                     : {}'.format(end_time - start_time))\n",
    "\n",
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"selfdrive_model.h5\")\n",
    "print ( \"  \")\n",
    "print ( \" .. model saved to selfdrive_model.h5 \")\n",
    "print ( \"  \")\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "# print(history_object.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# # # Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_producer2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d5fffc314fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_producer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_producer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_producer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_producer2' is not defined"
     ]
    }
   ],
   "source": [
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Convolution broken down in small pieces \n",
    "\n",
    "### Here I am trying to visualize the Convolution Layers to understand visually how many filters I should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print (\" Loading drive.h5 .......\")\n",
    "\n",
    "# from keras.models import load_model\n",
    "# from keras.models import Model\n",
    "\n",
    "# modelobj = load_model('drive.h5')\n",
    "# print (\" ..... model drive.h5 successfully loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this purpose I am loading a Test image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(py_training_samples_part1[3000], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load test images\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# test_images = []\n",
    "\n",
    "# image = cv2.imread('./test_images/center1.jpg')\n",
    "# image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "# test_images.append(image)\n",
    "\n",
    "\n",
    "# test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I am looking at the Image Crop if is well done in the right position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'cropping'\n",
    "# intermediate_layer_model = Model(inputs=modelobj.input,\n",
    "#                                  outputs=modelobj.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# intermediate_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Show the cropped images\n",
    "# def show_intermediate_output(image_ori, intermediate_output):\n",
    "#     print (intermediate_output.shape)\n",
    "#     depth = 0 \n",
    "#     %matplotlib inline\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(20, 100))\n",
    "#     new_image = []\n",
    "#     plt.subplot(40, 5, 1 )\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image_ori)\n",
    "#     for i in range(0,intermediate_output[0,0].shape[0]):\n",
    "#            single_output = intermediate_output[:,:,i]\n",
    "# #            print ( \"single_output.shape {}\".format(single_output.shape ))\n",
    "# #            print ( single_output)\n",
    "#            plt.subplot(40, 5, i+2 )\n",
    "#            plt.axis('off')\n",
    "#            single_output = single_output.astype(np.uint8)\n",
    "#            plt.imshow(single_output, cmap='gray')\n",
    "#     plt.show()    \n",
    "\n",
    "    \n",
    "# show_intermediate_output(test_images[0], intermediate_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the FIRST convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv1'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the SECOND convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv2'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv3'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv4'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from keras.utils.visualize_util import plot\n",
    "# from keras.models import load_model\n",
    "# %matplotlib inline\n",
    "\n",
    "# #visualize the model\n",
    "# modelobj = load_model('model.h5')\n",
    "# plot (modelobj, to_file='model.png')\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(100, 100))\n",
    "# image = cv2.imread('model.png')\n",
    "# image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "# plt.subplot(5, 5, 1)\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
